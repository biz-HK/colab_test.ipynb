{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIç”»åƒæ¤œæŸ»ã‚·ã‚¹ãƒ†ãƒ  - Colab UIæ¤œè¨¼\n",
    "ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªWebãƒ™ãƒ¼ã‚¹UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install torch torchvision opencv-python-headless pillow numpy ipywidgets -q\n",
    "print(\"ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from google.colab import files\n",
    "import io\n",
    "import base64\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ¢ãƒ‡ãƒ«å®šç¾©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel,self).__init__() \n",
    "        self.Encoder = nn.Sequential(self.create_convblock(3,16),\n",
    "                                     nn.MaxPool2d((2,2)),\n",
    "                                     self.create_convblock(16,32),\n",
    "                                     nn.MaxPool2d((2,2)),\n",
    "                                     self.create_convblock(32,64),\n",
    "                                     nn.MaxPool2d((2,2)),\n",
    "                                     self.create_convblock(64,128),\n",
    "                                     nn.MaxPool2d((2,2)),\n",
    "                                     self.create_convblock(128,256),\n",
    "                                     nn.MaxPool2d((2,2)),\n",
    "                                     self.create_convblock(256,512),\n",
    "                                    )\n",
    "        self.Decoder = nn.Sequential(self.create_deconvblock(512,256),\n",
    "                                     self.create_convblock(256,256),\n",
    "                                     self.create_deconvblock(256,128),\n",
    "                                     self.create_convblock(128,128),\n",
    "                                     self.create_deconvblock(128,64),\n",
    "                                     self.create_convblock(64,64),\n",
    "                                     self.create_deconvblock(64,32),\n",
    "                                     self.create_convblock(32,32),\n",
    "                                     self.create_deconvblock(32,16),\n",
    "                                     self.create_convblock(16,16),\n",
    "                                    )\n",
    "        self.last_layer = nn.Conv2d(16,3,1,1)\n",
    "                                        \n",
    "    def create_convblock(self,i_fn,o_fn):\n",
    "        conv_block = nn.Sequential(nn.Conv2d(i_fn,o_fn,3,1,1),\n",
    "                                   nn.BatchNorm2d(o_fn),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(o_fn,o_fn,3,1,1),\n",
    "                                   nn.BatchNorm2d(o_fn),\n",
    "                                   nn.ReLU()\n",
    "                                  )\n",
    "        return conv_block\n",
    "    \n",
    "    def create_deconvblock(self,i_fn , o_fn):\n",
    "        deconv_block = nn.Sequential(nn.ConvTranspose2d(i_fn, o_fn, kernel_size=2, stride=2),\n",
    "                                      nn.BatchNorm2d(o_fn),\n",
    "                                      nn.ReLU(),\n",
    "                                     )\n",
    "        return deconv_block\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.Encoder(x)\n",
    "        x = self.Decoder(x)\n",
    "        x = self.last_layer(x)           \n",
    "        return x\n",
    "\n",
    "print(\"ãƒ¢ãƒ‡ãƒ«å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°\n",
    "model = CustomModel()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "preprocess = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "current_image = None\n",
    "model_loaded = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†\")\n",
    "print(f\"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\n",
    "print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# ãƒœã‚¿ãƒ³\n",
    "load_model_btn = widgets.Button(description=\"ğŸ“ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\", button_style='info')\n",
    "load_image_btn = widgets.Button(description=\"ğŸ–¼ï¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\", button_style='primary')\n",
    "sample_btn = widgets.Button(description=\"ğŸ² ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ\", button_style='warning')\n",
    "inference_btn = widgets.Button(description=\"ğŸ” æ¨è«–å®Ÿè¡Œ\", button_style='success')\n",
    "\n",
    "# ã—ãã„å€¤ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼\n",
    "threshold_slider = widgets.FloatSlider(\n",
    "    value=0.01,\n",
    "    min=0.001,\n",
    "    max=0.1,\n",
    "    step=0.001,\n",
    "    description='ã—ãã„å€¤:',\n",
    "    readout_format='.4f'\n",
    ")\n",
    "\n",
    "# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º\n",
    "status_label = widgets.HTML(value=\"<b>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</b> ãƒ¢ãƒ‡ãƒ«æœªãƒ­ãƒ¼ãƒ‰\")\n",
    "\n",
    "# ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ\n",
    "control_box = widgets.HBox([load_model_btn, load_image_btn, sample_btn, inference_btn])\n",
    "param_box = widgets.HBox([threshold_slider])\n",
    "ui = widgets.VBox([status_label, control_box, param_box, output_area])\n",
    "\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½\n",
    "def load_model_callback(b):\n",
    "    global model, model_loaded\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"model.pthãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„...\")\n",
    "        \n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if 'model.pth' in uploaded:\n",
    "            try:\n",
    "                # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "                checkpoint = torch.load(io.BytesIO(uploaded['model.pth']), map_location=device)\n",
    "                model.load_state_dict(checkpoint)\n",
    "                model.eval()\n",
    "                model_loaded = True\n",
    "                \n",
    "                status_label.value = \"<b>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</b> <span style='color:green'>ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿</span>\"\n",
    "                print(\"âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        else:\n",
    "            print(\"âš ï¸ model.pthãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "\n",
    "load_model_btn.on_click(load_model_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½\n",
    "def load_image_callback(b):\n",
    "    global current_image\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(\"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„...\")\n",
    "        \n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        for filename, data in uploaded.items():\n",
    "            try:\n",
    "                current_image = Image.open(io.BytesIO(data)).convert('RGB')\n",
    "                \n",
    "                # ç”»åƒè¡¨ç¤º\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(current_image)\n",
    "                plt.title(f\"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ: {filename}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                print(f\"âœ… ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ: {filename}\")\n",
    "                print(f\"ã‚µã‚¤ã‚º: {current_image.size}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ç”»åƒãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "load_image_btn.on_click(load_image_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒ³ãƒ—ãƒ«ç”»åƒç”Ÿæˆ\n",
    "def sample_callback(b):\n",
    "    global current_image\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ç”Ÿæˆ\n",
    "        np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚\n",
    "        sample_type = np.random.choice(['normal', 'anomaly'])\n",
    "        \n",
    "        if sample_type == 'normal':\n",
    "            # æ­£å¸¸ç”»åƒï¼ˆä¸€æ§˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\n",
    "            img_array = np.ones((256, 256, 3), dtype=np.uint8) * 128\n",
    "            img_array += np.random.normal(0, 10, (256, 256, 3)).astype(np.uint8)\n",
    "            title = \"ã‚µãƒ³ãƒ—ãƒ«ç”»åƒï¼ˆæ­£å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\"\n",
    "        else:\n",
    "            # ç•°å¸¸ç”»åƒï¼ˆãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºï¼‰\n",
    "            img_array = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "            title = \"ã‚µãƒ³ãƒ—ãƒ«ç”»åƒï¼ˆç•°å¸¸ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰\"\n",
    "        \n",
    "        current_image = Image.fromarray(img_array)\n",
    "        \n",
    "        # ç”»åƒè¡¨ç¤º\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(current_image)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"âœ… {title}ã‚’ç”Ÿæˆã—ã¾ã—ãŸ\")\n",
    "\n",
    "sample_btn.on_click(sample_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨è«–å®Ÿè¡Œæ©Ÿèƒ½\n",
    "def inference_callback(b):\n",
    "    global current_image, model\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if current_image is None:\n",
    "            print(\"âš ï¸ ç”»åƒã‚’å…ˆã«ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            print(\"ğŸ” æ¨è«–å®Ÿè¡Œä¸­...\")\n",
    "            \n",
    "            # å‰å‡¦ç†\n",
    "            input_tensor = preprocess(current_image).unsqueeze(0).to(device)\n",
    "            \n",
    "            # æ¨è«–\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor)\n",
    "            \n",
    "            # å¾Œå‡¦ç†\n",
    "            input_np = input_tensor.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "            output_np = output.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "            \n",
    "            input_np = np.clip(input_np, 0, 1)\n",
    "            output_np = np.clip(output_np, 0, 1)\n",
    "            \n",
    "            # å·®åˆ†è¨ˆç®—\n",
    "            diff = np.abs(input_np - output_np)\n",
    "            mse = np.mean((input_np - output_np) ** 2)\n",
    "            \n",
    "            # ç•°å¸¸åˆ¤å®š\n",
    "            threshold = threshold_slider.value\n",
    "            is_anomaly = mse > threshold\n",
    "            \n",
    "            # çµæœè¡¨ç¤º\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            axes[0].imshow(input_np)\n",
    "            axes[0].set_title(\"å…¥åŠ›ç”»åƒ\")\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            axes[1].imshow(output_np)\n",
    "            axes[1].set_title(\"å¾©å…ƒç”»åƒ\")\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            axes[2].imshow(diff)\n",
    "            axes[2].set_title(\"å·®åˆ†ç”»åƒ\")\n",
    "            axes[2].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # çµæœã‚µãƒãƒªãƒ¼\n",
    "            print(\"=\"*50)\n",
    "            print(\"ğŸ“Š æ¨è«–çµæœ\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"å¾©å…ƒèª¤å·® (MSE): {mse:.6f}\")\n",
    "            print(f\"åˆ¤å®šã—ãã„å€¤: {threshold:.6f}\")\n",
    "            print(f\"æœ€å¤§å·®åˆ†: {np.max(diff):.6f}\")\n",
    "            print(f\"å¹³å‡å·®åˆ†: {np.mean(diff):.6f}\")\n",
    "            print(f\"\")\n",
    "            \n",
    "            if is_anomaly:\n",
    "                print(\"ğŸš¨ åˆ¤å®š: ç•°å¸¸æ¤œå‡º\")\n",
    "                print(f\"   å¾©å…ƒèª¤å·®ãŒé–¾å€¤ {threshold:.6f} ã‚’ä¸Šå›ã‚Šã¾ã—ãŸ\")\n",
    "            else:\n",
    "                print(\"âœ… åˆ¤å®š: æ­£å¸¸\")\n",
    "                print(f\"   å¾©å…ƒèª¤å·®ãŒé–¾å€¤ {threshold:.6f} ä»¥ä¸‹ã§ã™\")\n",
    "            \n",
    "            if not model_loaded:\n",
    "                print(\"\")\n",
    "                print(\"âš ï¸ æ³¨æ„: å­¦ç¿’å‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™\")\n",
    "                print(\"   å®Ÿéš›ã®ç•°å¸¸æ¤œçŸ¥æ€§èƒ½ã¯æœŸå¾…ã§ãã¾ã›ã‚“\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æ¨è«–ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "\n",
    "inference_btn.on_click(inference_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰** (ã‚ªãƒ—ã‚·ãƒ§ãƒ³): å­¦ç¿’æ¸ˆã¿model.pthã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "2. **ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** ã¾ãŸã¯ **ã‚µãƒ³ãƒ—ãƒ«ç”»åƒ** ã§æ¤œè¨¼ç”¨ç”»åƒã‚’æº–å‚™\n",
    "3. **ã—ãã„å€¤ã‚’èª¿æ•´** (å¿…è¦ã«å¿œã˜ã¦)\n",
    "4. **æ¨è«–å®Ÿè¡Œ** ã§ç•°å¸¸æ¤œçŸ¥ã‚’å®Ÿè¡Œ\n",
    "\n",
    "### ç‰¹å¾´\n",
    "- ğŸ“± ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªWebãƒ™ãƒ¼ã‚¹UI\n",
    "- ğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ çµæœè¡¨ç¤º\n",
    "- ğŸ“Š è¦–è¦šçš„ãªæ¯”è¼ƒï¼ˆå…¥åŠ›ãƒ»å¾©å…ƒãƒ»å·®åˆ†ï¼‰\n",
    "- âš™ï¸ ã—ãã„å€¤ã®å‹•çš„èª¿æ•´\n",
    "- ğŸ² ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ã®å‹•ä½œç¢ºèª"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
