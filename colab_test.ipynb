{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biz-HK/colab_test.ipynb/blob/main/colab_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUg05vAhzTOn"
      },
      "source": [
        "# AI画像検査システム - クラウド環境テスト\n",
        "Google Colabで実行可能なテストコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy5vzI64zTOo"
      },
      "source": [
        "## 1. 環境セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5HMLuZ7-zTOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15c717e-a587-45d9-e6d6-b9ab7c8e9e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hパッケージインストール完了\n"
          ]
        }
      ],
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install torch torchvision opencv-python-headless pillow numpy -q\n",
        "print(\"パッケージインストール完了\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pTd7KF7hzTOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb2aa45-b5f3-439f-f8d5-ddedb6bc9449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: False\n",
            "OpenCV version: 4.12.0\n"
          ]
        }
      ],
      "source": [
        "# インポートテスト\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOnpo-FizTOq"
      },
      "source": [
        "## 2. モデル定義（元のコードから）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "72BDN7yLzTOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27bfeba-aaee-4257-9283-833da9affdfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデル定義完了\n"
          ]
        }
      ],
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel,self).__init__()\n",
        "        self.Encoder = nn.Sequential(self.create_convblock(3,16),     #256\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(16,32),    #128\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(32,64),    #64\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(64,128),   #32\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(128,256),  #16\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(256,512),  #8\n",
        "                                    )\n",
        "        self.Decoder = nn.Sequential(self.create_deconvblock(512,256), #16\n",
        "                                     self.create_convblock(256,256),\n",
        "                                     self.create_deconvblock(256,128), #32\n",
        "                                     self.create_convblock(128,128),\n",
        "                                     self.create_deconvblock(128,64),  #64\n",
        "                                     self.create_convblock(64,64),\n",
        "                                     self.create_deconvblock(64,32),   #128\n",
        "                                     self.create_convblock(32,32),\n",
        "                                     self.create_deconvblock(32,16),   #256\n",
        "                                     self.create_convblock(16,16),\n",
        "                                    )\n",
        "        self.last_layer = nn.Conv2d(16,3,1,1)\n",
        "\n",
        "    def create_convblock(self,i_fn,o_fn):\n",
        "        conv_block = nn.Sequential(nn.Conv2d(i_fn,o_fn,3,1,1),\n",
        "                                   nn.BatchNorm2d(o_fn),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Conv2d(o_fn,o_fn,3,1,1),\n",
        "                                   nn.BatchNorm2d(o_fn),\n",
        "                                   nn.ReLU()\n",
        "                                  )\n",
        "        return conv_block\n",
        "\n",
        "    def create_deconvblock(self,i_fn , o_fn):\n",
        "        deconv_block = nn.Sequential(nn.ConvTranspose2d(i_fn, o_fn, kernel_size=2, stride=2),\n",
        "                                      nn.BatchNorm2d(o_fn),\n",
        "                                      nn.ReLU(),\n",
        "                                     )\n",
        "        return deconv_block\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        x = self.last_layer(x)\n",
        "        return x\n",
        "\n",
        "print(\"モデル定義完了\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KYdutmqzTOq"
      },
      "source": [
        "## 3. モデル作成とパラメータ確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NiiG-g2CzTOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6e500e2-b59d-4ee4-accc-8f8d58f0fbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルパラメータ数: 6,996,979\n",
            "使用デバイス: cpu\n"
          ]
        }
      ],
      "source": [
        "# モデル作成\n",
        "model = CustomModel()\n",
        "\n",
        "# GPU使用可能なら移動\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# モデルパラメータ数\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"モデルパラメータ数: {total_params:,}\")\n",
        "print(f\"使用デバイス: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXDheiLzTOq"
      },
      "source": [
        "## 4. ダミー画像でテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0GwI9GpszTOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f22cf2a7-520b-457c-d7e3-4e932276204a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力テンソルサイズ: torch.Size([1, 3, 256, 256])\n",
            "出力テンソルサイズ: torch.Size([1, 3, 256, 256])\n",
            "推論成功！\n"
          ]
        }
      ],
      "source": [
        "# ダミー画像生成\n",
        "dummy_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
        "\n",
        "# 前処理\n",
        "preprocess = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "# PIL画像に変換してテンソル化\n",
        "pil_image = Image.fromarray(dummy_image)\n",
        "input_tensor = preprocess(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "print(f\"入力テンソルサイズ: {input_tensor.shape}\")\n",
        "\n",
        "# 推論実行\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "\n",
        "print(f\"出力テンソルサイズ: {output.shape}\")\n",
        "print(\"推論成功！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44hpswUdzTOr"
      },
      "source": [
        "## 5. 異常検知シミュレーション"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mA1Exb0GzTOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8af4ab-3b54-4195-c5b8-fff9c8aa0ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正常画像の復元誤差: 0.173182\n",
            "異常画像の復元誤差: 0.253664\n",
            "\n",
            "※学習前のモデルなので、実際の異常検知性能は期待できません\n",
            "  学習後は異常画像の誤差が大きくなります\n"
          ]
        }
      ],
      "source": [
        "def calculate_reconstruction_error(original, reconstructed):\n",
        "    \"\"\"復元誤差を計算（MSE）\"\"\"\n",
        "    mse = torch.mean((original - reconstructed) ** 2)\n",
        "    return mse.item()\n",
        "\n",
        "# 正常画像シミュレーション（一様な画像）\n",
        "normal_image = np.ones((256, 256, 3), dtype=np.uint8) * 128\n",
        "normal_tensor = preprocess(Image.fromarray(normal_image)).unsqueeze(0).to(device)\n",
        "\n",
        "# 異常画像シミュレーション（ランダムノイズ）\n",
        "anomaly_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
        "anomaly_tensor = preprocess(Image.fromarray(anomaly_image)).unsqueeze(0).to(device)\n",
        "\n",
        "# 推論と誤差計算\n",
        "with torch.no_grad():\n",
        "    normal_output = model(normal_tensor)\n",
        "    anomaly_output = model(anomaly_tensor)\n",
        "\n",
        "    normal_error = calculate_reconstruction_error(normal_tensor, normal_output)\n",
        "    anomaly_error = calculate_reconstruction_error(anomaly_tensor, anomaly_output)\n",
        "\n",
        "print(f\"正常画像の復元誤差: {normal_error:.6f}\")\n",
        "print(f\"異常画像の復元誤差: {anomaly_error:.6f}\")\n",
        "print(f\"\\n※学習前のモデルなので、実際の異常検知性能は期待できません\")\n",
        "print(f\"  学習後は異常画像の誤差が大きくなります\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwJ8evjszTOr"
      },
      "source": [
        "## 6. メモリ使用量チェック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "60yGVYFqzTOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47853c4-6e4b-4b2c-bbac-4d1780fae1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU メモリ使用量: 643.1 MB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "# CPU メモリ\n",
        "process = psutil.Process(os.getpid())\n",
        "mem_info = process.memory_info()\n",
        "print(f\"CPU メモリ使用量: {mem_info.rss / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# GPU メモリ（利用可能な場合）\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU メモリ使用量: {torch.cuda.memory_allocated() / 1024 / 1024:.1f} MB\")\n",
        "    print(f\"GPU メモリ予約量: {torch.cuda.memory_reserved() / 1024 / 1024:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ83gOGczTOr"
      },
      "source": [
        "## 7. ベンチマークテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXjiLrbVzTOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef282b7-3e29-433b-b338-88ef58170564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "バッチサイズ  1:   4.77 FPS\n",
            "バッチサイズ  4:   4.74 FPS\n",
            "バッチサイズ  8:   4.31 FPS\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# バッチサイズごとの処理速度測定\n",
        "batch_sizes = [1, 4, 8, 16]\n",
        "results = []\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    # ダミーバッチ作成\n",
        "    batch = torch.randn(batch_size, 3, 256, 256).to(device)\n",
        "\n",
        "    # ウォームアップ\n",
        "    for _ in range(3):\n",
        "        _ = model(batch)\n",
        "\n",
        "    # 計測\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(10):\n",
        "        _ = model(batch)\n",
        "\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    fps = (batch_size * 10) / elapsed\n",
        "    results.append((batch_size, fps))\n",
        "    print(f\"バッチサイズ {batch_size:2d}: {fps:6.2f} FPS\")\n",
        "\n",
        "print(f\"\\n最適バッチサイズ: {max(results, key=lambda x: x[1])[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2bJNqXzTOr"
      },
      "source": [
        "## まとめ\n",
        "このノートブックをGoogle Colabにアップロードして実行することで：\n",
        "- PyTorch/OpenCVの動作確認\n",
        "- モデルアーキテクチャの検証\n",
        "- GPU利用可能性の確認\n",
        "- パフォーマンス測定\n",
        "\n",
        "が可能です。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}