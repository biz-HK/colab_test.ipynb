{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/biz-HK/colab_test.ipynb/blob/main/colab_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUg05vAhzTOn"
      },
      "source": [
        "# AI画像検査システム - クラウド環境テスト\n",
        "Google Colabで実行可能なテストコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy5vzI64zTOo"
      },
      "source": [
        "## 1. 環境セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HMLuZ7-zTOp"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリのインストール\n",
        "!pip install torch torchvision opencv-python-headless pillow numpy -q\n",
        "print(\"パッケージインストール完了\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTd7KF7hzTOp"
      },
      "outputs": [],
      "source": [
        "# インポートテスト\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"OpenCV version: {cv2.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOnpo-FizTOq"
      },
      "source": [
        "## 2. モデル定義（元のコードから）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72BDN7yLzTOq"
      },
      "outputs": [],
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel,self).__init__()\n",
        "        self.Encoder = nn.Sequential(self.create_convblock(3,16),     #256\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(16,32),    #128\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(32,64),    #64\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(64,128),   #32\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(128,256),  #16\n",
        "                                     nn.MaxPool2d((2,2)),\n",
        "                                     self.create_convblock(256,512),  #8\n",
        "                                    )\n",
        "        self.Decoder = nn.Sequential(self.create_deconvblock(512,256), #16\n",
        "                                     self.create_convblock(256,256),\n",
        "                                     self.create_deconvblock(256,128), #32\n",
        "                                     self.create_convblock(128,128),\n",
        "                                     self.create_deconvblock(128,64),  #64\n",
        "                                     self.create_convblock(64,64),\n",
        "                                     self.create_deconvblock(64,32),   #128\n",
        "                                     self.create_convblock(32,32),\n",
        "                                     self.create_deconvblock(32,16),   #256\n",
        "                                     self.create_convblock(16,16),\n",
        "                                    )\n",
        "        self.last_layer = nn.Conv2d(16,3,1,1)\n",
        "\n",
        "    def create_convblock(self,i_fn,o_fn):\n",
        "        conv_block = nn.Sequential(nn.Conv2d(i_fn,o_fn,3,1,1),\n",
        "                                   nn.BatchNorm2d(o_fn),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Conv2d(o_fn,o_fn,3,1,1),\n",
        "                                   nn.BatchNorm2d(o_fn),\n",
        "                                   nn.ReLU()\n",
        "                                  )\n",
        "        return conv_block\n",
        "\n",
        "    def create_deconvblock(self,i_fn , o_fn):\n",
        "        deconv_block = nn.Sequential(nn.ConvTranspose2d(i_fn, o_fn, kernel_size=2, stride=2),\n",
        "                                      nn.BatchNorm2d(o_fn),\n",
        "                                      nn.ReLU(),\n",
        "                                     )\n",
        "        return deconv_block\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.Encoder(x)\n",
        "        x = self.Decoder(x)\n",
        "        x = self.last_layer(x)\n",
        "        return x\n",
        "\n",
        "print(\"モデル定義完了\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KYdutmqzTOq"
      },
      "source": [
        "## 3. モデル作成とパラメータ確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiiG-g2CzTOq"
      },
      "outputs": [],
      "source": [
        "# モデル作成\n",
        "model = CustomModel()\n",
        "\n",
        "# GPU使用可能なら移動\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# モデルパラメータ数\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"モデルパラメータ数: {total_params:,}\")\n",
        "print(f\"使用デバイス: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXDheiLzTOq"
      },
      "source": [
        "## 4. ダミー画像でテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GwI9GpszTOq"
      },
      "outputs": [],
      "source": [
        "# ダミー画像生成\n",
        "dummy_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
        "\n",
        "# 前処理\n",
        "preprocess = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "# PIL画像に変換してテンソル化\n",
        "pil_image = Image.fromarray(dummy_image)\n",
        "input_tensor = preprocess(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "print(f\"入力テンソルサイズ: {input_tensor.shape}\")\n",
        "\n",
        "# 推論実行\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "\n",
        "print(f\"出力テンソルサイズ: {output.shape}\")\n",
        "print(\"推論成功！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44hpswUdzTOr"
      },
      "source": [
        "## 5. 異常検知シミュレーション"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA1Exb0GzTOr"
      },
      "outputs": [],
      "source": [
        "def calculate_reconstruction_error(original, reconstructed):\n",
        "    \"\"\"復元誤差を計算（MSE）\"\"\"\n",
        "    mse = torch.mean((original - reconstructed) ** 2)\n",
        "    return mse.item()\n",
        "\n",
        "# 正常画像シミュレーション（一様な画像）\n",
        "normal_image = np.ones((256, 256, 3), dtype=np.uint8) * 128\n",
        "normal_tensor = preprocess(Image.fromarray(normal_image)).unsqueeze(0).to(device)\n",
        "\n",
        "# 異常画像シミュレーション（ランダムノイズ）\n",
        "anomaly_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
        "anomaly_tensor = preprocess(Image.fromarray(anomaly_image)).unsqueeze(0).to(device)\n",
        "\n",
        "# 推論と誤差計算\n",
        "with torch.no_grad():\n",
        "    normal_output = model(normal_tensor)\n",
        "    anomaly_output = model(anomaly_tensor)\n",
        "\n",
        "    normal_error = calculate_reconstruction_error(normal_tensor, normal_output)\n",
        "    anomaly_error = calculate_reconstruction_error(anomaly_tensor, anomaly_output)\n",
        "\n",
        "print(f\"正常画像の復元誤差: {normal_error:.6f}\")\n",
        "print(f\"異常画像の復元誤差: {anomaly_error:.6f}\")\n",
        "print(f\"\\n※学習前のモデルなので、実際の異常検知性能は期待できません\")\n",
        "print(f\"  学習後は異常画像の誤差が大きくなります\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwJ8evjszTOr"
      },
      "source": [
        "## 6. メモリ使用量チェック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60yGVYFqzTOr"
      },
      "outputs": [],
      "source": [
        "import psutil\n",
        "import os\n",
        "\n",
        "# CPU メモリ\n",
        "process = psutil.Process(os.getpid())\n",
        "mem_info = process.memory_info()\n",
        "print(f\"CPU メモリ使用量: {mem_info.rss / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# GPU メモリ（利用可能な場合）\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU メモリ使用量: {torch.cuda.memory_allocated() / 1024 / 1024:.1f} MB\")\n",
        "    print(f\"GPU メモリ予約量: {torch.cuda.memory_reserved() / 1024 / 1024:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ83gOGczTOr"
      },
      "source": [
        "## 7. ベンチマークテスト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXjiLrbVzTOr"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# バッチサイズごとの処理速度測定\n",
        "batch_sizes = [1, 4, 8, 16]\n",
        "results = []\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    # ダミーバッチ作成\n",
        "    batch = torch.randn(batch_size, 3, 256, 256).to(device)\n",
        "\n",
        "    # ウォームアップ\n",
        "    for _ in range(3):\n",
        "        _ = model(batch)\n",
        "\n",
        "    # 計測\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    start = time.time()\n",
        "\n",
        "    for _ in range(10):\n",
        "        _ = model(batch)\n",
        "\n",
        "    torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    fps = (batch_size * 10) / elapsed\n",
        "    results.append((batch_size, fps))\n",
        "    print(f\"バッチサイズ {batch_size:2d}: {fps:6.2f} FPS\")\n",
        "\n",
        "print(f\"\\n最適バッチサイズ: {max(results, key=lambda x: x[1])[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki2bJNqXzTOr"
      },
      "source": [
        "## まとめ\n",
        "このノートブックをGoogle Colabにアップロードして実行することで：\n",
        "- PyTorch/OpenCVの動作確認\n",
        "- モデルアーキテクチャの検証\n",
        "- GPU利用可能性の確認\n",
        "- パフォーマンス測定\n",
        "\n",
        "が可能です。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colabから直接GitHubリポジトリを開く\n",
        "# ファイル > GitHubから開く\n",
        "# または\n",
        "# ファイル > GitHubにコピーを保存\n"
      ],
      "metadata": {
        "id": "km91o4yG0VS6"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}